# What Gets Saved During Benchmarking

## âœ… What IS Saved (Logs & Profiles Only)

### Benchmark Results
```
benchmark_results/
â””â”€â”€ benchmark_{platform}_{timestamp}.json
```

**Size**: ~5-10 KB per run  
**Contents**:
- Platform info (CUDA/ROCm)
- GPU specifications
- Performance metrics (step times, throughput)
- Memory usage statistics
- Per-core metrics
- Raw timing data

**Purpose**: Lightweight profiling data for AMD vs NVIDIA comparison

### Console Output
- Real-time training progress
- Step timing information
- Benchmark summary at the end

## âŒ What is NOT Saved

### Model Checkpoints
- âœ— No model weights
- âœ— No optimizer states
- âœ— No training state

### TensorBoard Logs
- âœ— No TensorBoard events
- âœ— No metric histories
- âœ— No computational graphs

### WandB Logs
- âœ— No WandB uploads
- âœ— No experiment tracking

### Validation Results
- âœ— No validation checkpoints
- âœ— No validation metrics

### Other Intermediate Files
- âœ— No distributed checkpoint files
- âœ— No async save states
- âœ— No hparams files

## Configuration

All three training scripts are configured to disable saves:

```python
# DISABLE ALL CHECKPOINTING AND INTERMEDIATE SAVES
recipe.trainer.enable_checkpointing = False
recipe.log.ckpt = None
recipe.resume = None

# Disable TensorBoard and other loggers
recipe.log.tensorboard = None
recipe.log.wandb = None

# Disable validation
recipe.trainer.val_check_interval = None
recipe.trainer.check_val_every_n_epoch = None
```

## What You'll See

### On Disk (After Training)
```
week-02/code/
â””â”€â”€ benchmark_results/
    â”œâ”€â”€ benchmark_cuda_20260105_143022.json    (~8 KB)
    â””â”€â”€ benchmark_rocm_20260105_095927.json    (~8 KB)
```

**Total disk usage**: ~16 KB for both platforms

### No Checkpoint Directory
The `/checkpoints` directory specified in the recipe will NOT be created or used.

## Benefits

1. **Fast**: No time wasted saving large checkpoints
2. **Clean**: No clutter from intermediate files
3. **Portable**: Small JSON files easy to transfer
4. **Focused**: Only profiling data for comparison

## If You Need Full Logging

To re-enable full logging and checkpointing, comment out these lines:

```python
# recipe.log.ckpt = None              # Uncomment to enable checkpoints
# recipe.log.tensorboard = None       # Uncomment to enable TensorBoard
# recipe.trainer.enable_checkpointing = False  # Change to True
```

## Verifying What's Saved

### Check Benchmark Results
```bash
ls -lh benchmark_results/
```

### View Benchmark Contents
```bash
cat benchmark_results/benchmark_*.json | python3 -m json.tool
```

### Verify No Checkpoints
```bash
# Should be empty or not exist
ls /checkpoints/ 2>/dev/null || echo "No checkpoint directory (correct!)"
```

## Size Comparison

| Item | Saved? | Typical Size |
|------|--------|--------------|
| Benchmark JSON | âœ… YES | 5-10 KB |
| Model Checkpoint | âŒ NO | 8-16 GB |
| Optimizer State | âŒ NO | 16-32 GB |
| TensorBoard Events | âŒ NO | 100-500 MB |
| Total | | **~8 KB** |

**Space saved**: ~30+ GB per run! ğŸ‰

## Summary

**You save**: Lightweight benchmark profiles (~8 KB JSON files)  
**You skip**: Everything else (checkpoints, logs, intermediate files)  
**Result**: Fast, clean benchmarking runs with just the profiling data you need

---

**Modified files**:
- `pretrain_llama.py`
- `pretrain_qwen.py`
- `pretrain_mistral.py`

All configured to save only benchmark results!

