experiment:
  name: "tprimat_benchmark"
  description: "LLM training benchmark comparing AMD vs NVIDIA hardware"
  version: "1.0"
  profiling: false                    # Enable NVIDIA Nsight Systems profiling
  logging: true                       # Enable detailed logging (console + file)

hardware:
  platforms:
    nvidia:
      gpu_model: "H100"
      memory_per_gpu_gb: 80
      num_gpus: 8
      software_stack: "cuda"
      framework: "nemo"
    
    amd:
      gpu_model: "MI300X"
      memory_per_gpu_gb: 192
      num_gpus: 8
      software_stack: "rocm"
      framework: "primus"

models:
  llama:
    name: "llama3.1_8b"
    full_name: "Llama 3.1 8B"
    num_parameters: 8.0e9
    num_layers: 32
    hidden_size: 4096
    num_attention_heads: 32
    nemo_recipe: "llama31_8b.pretrain_recipe"
    primus_recipe: "llama3.1_8B-BF16-pretrain.yaml"
    # Model-specific data paths (optional, overrides global training.data)
    dataset_path: "/data/llama_dataset_text_document"
    tokenizer_path: "meta-llama/Llama-3.1-8B"
    
  qwen:
    name: "qwen2.5_7b"
    full_name: "Qwen 2.5 7B"
    num_parameters: 7.6e9
    num_layers: 28
    hidden_size: 3584
    num_attention_heads: 28
    prim_config: "examples/megatron/configs/MI300X/qwen2.5_7B-BF16-pretrain.yaml"
    nemo_recipe: "qwen25_7b.pretrain_recipe"
    # Model-specific data paths (optional, overrides global training.data)
    # Using same dataset as Llama for benchmarking (computational workload is what matters)
    dataset_path: "/data/llama_dataset_text_document"
    tokenizer_path: "Qwen/Qwen2.5-7B"

training:
  general:
    seed: 42                        # Random seed for reproducibility
  data:
    micro_batch_size: 1             # Per-GPU batch size per accumulation step
    global_batch_size: 128          # Total batch size across all GPUs
    seq_length: 2048                # Sequence length in tokens
    # Global dataset paths (optional, can be overridden by model-specific paths)
    # dataset_path: "/data/dataset_text_document"
    # tokenizer_path: "model/tokenizer"
  duration:
    max_steps: 500                    # Number of training steps
    train_iters: 500                  # Alternative name used by Primus
  optimizer:
    type: "adam"
    learning_rate: 3.0e-4
    warmup_steps: 50                # Warmup steps (20% of training)
    weight_decay: 0.1
    beta1: 0.9
    beta2: 0.95
  precision:
    default: "bf16"                 # Options: fp32, fp16, bf16, fp8
    fp8_hybrid: false               # Enable FP8 hybrid mode (H100 specific)
    fp8_param: false                # Store parameters in FP8
  checkpointing:
    enabled: false
    save_interval: 1000
    keep_last_n: 2

parallelism:
  # Maximum Performance: Platform-specific tuning to maximize throughput.
  # NVIDIA: Higher TP to fit model in 80GB, balanced with DP for throughput.
  # AMD: Leverages 192GB memory with TP=1 for max DP, minimal communication.
  # Trade-off: Different settings per platform = non-identical compute paths.
  maximum_performance: # 00
    llama:
      nvidia:
        tensor_model_parallel_size: 4    # TP=4
        pipeline_model_parallel_size: 1  # PP=1
        data_parallel_size: 2            # 8/(4*1) = 2
        gradient_accumulation_steps: 64  # 128/(1*2) = 64
      amd:
        tensor_model_parallel_size: 1    # TP=1 (no tensor parallelism - minimal overhead)
        pipeline_model_parallel_size: 1  # PP=1
        data_parallel_size: 2            # 2/(1*1) = 2 (match NVIDIA's DP)
        gradient_accumulation_steps: 64  # 128/(1*2) = 64 (match NVIDIA's sync frequency)
    qwen:
      nvidia:
        tensor_model_parallel_size: 4    # TP=4
        pipeline_model_parallel_size: 2  # PP=2
        data_parallel_size: 1            # 8/(4*2) = 1
        gradient_accumulation_steps: 128 # 128/(1*1) = 128
      amd:
        tensor_model_parallel_size: 1    # TP=1 (no tensor parallelism - minimal overhead)
        pipeline_model_parallel_size: 1  # PP=1
        data_parallel_size: 1            # 1/(1*1) = 1 (single GPU group)
        gradient_accumulation_steps: 128 # 128/(1*1) = 128 (match NVIDIA's sync frequency)
  
  # Truly Identical: All platforms use exactly the same parallelism settings.
  # Ensures apples-to-apples comparison across hardware.
  # Same TP/PP/DP means identical compute graph and communication patterns.
  # Trade-off: May not fully utilize platform advantages (AMD's larger mem).
  truly_identical: # 01
    llama:
      nvidia:
        tensor_model_parallel_size: 4
        pipeline_model_parallel_size: 1
        data_parallel_size: 2
        gradient_accumulation_steps: 64
      amd:
        tensor_model_parallel_size: 4
        pipeline_model_parallel_size: 1
        data_parallel_size: 2
        gradient_accumulation_steps: 64
    qwen:
      nvidia:
        tensor_model_parallel_size: 4
        pipeline_model_parallel_size: 1
        data_parallel_size: 2
        gradient_accumulation_steps: 64
      amd:
        tensor_model_parallel_size: 4
        pipeline_model_parallel_size: 1
        data_parallel_size: 2
        gradient_accumulation_steps: 64 
  
  # Memory Optimized: Prioritizes reducing memory footprint per GPU.
  # Higher TP and PP to shard model weights and activations across GPUs.
  # Enables training larger models or larger batch sizes within memory.
  # Trade-off: Increased communication overhead reduces raw throughput.
  # Note: TP must divide attention heads evenly (Llama:32, Qwen:28 heads).
  memory_optimized: # 02
    llama:
      nvidia:
        tensor_model_parallel_size: 4    # TP=4 (reduces mem, avoids excess comm)
        pipeline_model_parallel_size: 2  # PP=2 (further reduce memory per GPU)
        data_parallel_size: 1            # 8/(4*2) = 1
        gradient_accumulation_steps: 128 # 128/(1*1) = 128
      amd:
        tensor_model_parallel_size: 2    # TP=2 (conservative given 192GB)
        pipeline_model_parallel_size: 1  # PP=1
        data_parallel_size: 4            # 8/(2*1) = 4
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
    qwen:
      nvidia:
        tensor_model_parallel_size: 4    # TP=4 (max compatible with 28 heads)
        pipeline_model_parallel_size: 2  # PP=2 (further reduce memory per GPU)
        data_parallel_size: 1            # 8/(4*2) = 1
        gradient_accumulation_steps: 128 # 128/(1*1) = 128
      amd:
        tensor_model_parallel_size: 2    # TP=2 (28 heads / 2 = 14 per GPU)
        pipeline_model_parallel_size: 1  # PP=1
        data_parallel_size: 4            # 8/(2*1) = 4
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
  
  # Minimal Communication: Eliminates model parallelism to minimize GPU comm.
  # TP=1, PP=1 means entire model fits on each GPU (no sharding).
  # Moderate DP=4 to reduce per-step communication overhead.
  # Trade-off: Requires sufficient GPU memory; best for smaller models.
  minimal_communication: # 03
    llama:
      nvidia:
        tensor_model_parallel_size: 1    # TP=1 (no tensor parallel comm)
        pipeline_model_parallel_size: 1  # PP=1 (no pipeline bubbles)
        data_parallel_size: 4            # Reduced DP to limit all-reduce traffic
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
      amd:
        tensor_model_parallel_size: 1    # TP=1 (no tensor parallel comm)
        pipeline_model_parallel_size: 1  # PP=1 (no pipeline bubbles)
        data_parallel_size: 4            # Reduced DP to limit all-reduce traffic
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
    qwen:
      nvidia:
        tensor_model_parallel_size: 1    # TP=1 (no tensor parallel comm)
        pipeline_model_parallel_size: 1  # PP=1 (no pipeline bubbles)
        data_parallel_size: 4            # Reduced DP to limit all-reduce traffic
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
      amd:
        tensor_model_parallel_size: 1    # TP=1 (no tensor parallel comm)
        pipeline_model_parallel_size: 1  # PP=1 (no pipeline bubbles)
        data_parallel_size: 4            # Reduced DP to limit all-reduce traffic
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
  
  # Balanced: Uses moderate tensor parallelism (TP=2) providing trade-off:
  # - Memory efficiency: TP=2 reduces memory per GPU by splitting weights
  # - Communication overhead: Lower TP means less all-reduce communication
  # - Compute utilization: Not over-sharding, each GPU has meaningful work
  balanced: # 04
    llama:
      nvidia:
        tensor_model_parallel_size: 2    # TP=2 (moderate sharding)
        pipeline_model_parallel_size: 1  # PP=1
        data_parallel_size: 4            # 8/(2*1) = 4
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
      amd:
        tensor_model_parallel_size: 2    # TP=2 (moderate sharding)
        pipeline_model_parallel_size: 1  # PP=1
        data_parallel_size: 4            # 8/(2*1) = 4
        gradient_accumulation_steps: 32  # 128/(1*4) = 32
    qwen:
      nvidia:
        tensor_model_parallel_size: 2    # TP=2 (moderate sharding)
        pipeline_model_parallel_size: 2  # PP=2
        data_parallel_size: 2            # 8/(2*2) = 2
        gradient_accumulation_steps: 64  # 128/(1*2) = 64
      amd:
        tensor_model_parallel_size: 2    # TP=2 (moderate sharding)
        pipeline_model_parallel_size: 2  # PP=2
        data_parallel_size: 2            # 8/(2*2) = 2
        gradient_accumulation_steps: 64  # 128/(1*2) = 64

platform_optimizations:
  amd:
    precision: "bf16"
    fp8_hybrid: false
    fp8_param: false
    activation_checkpointing: false
    gradient_checkpointing: false

paths:
  primus:
    installation: "${PRIMUS_PATH:-/workspace/Primus}"
    config_dir: "examples/megatron/configs/MI300X"
    run_script: "./examples/run_pretrain.sh"
  tprimat:
    base_dir: "."
    output_dir: "./output"
    logs_dir: "./output"

